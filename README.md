# auto_test_bot
# Framework de Testing Inteligente y Autocurativo

## ğŸ¯ Objetivo
DiseÃ±ar un framework de automatizaciÃ³n de pruebas end-to-end con Playwright + TypeScript, que integre capacidades de self-healing, machine learning para detecciÃ³n de patrones de fallos, y generaciÃ³n de reportes inteligentes. El bot usarÃ¡ Python para el backend de IA.

## ğŸ§± MÃ³dulos del Proyecto

### 1. Playwright + TypeScript Core
- Modulariza el framework con Page Object Model + Fixtures.
- Implementa pruebas para una web page.
- AÃ±ade lÃ³gica de retry inteligente y logging personalizado.

### 2. Self-Healing Engine (Python + ML)
- Usa Python para analizar logs de fallos y detectar patrones (por ejemplo, cambios en selectores).
- Entrena un modelo simple (Random Forest o SVM) para predecir si un test fallarÃ¡ por selector roto, timeout, o error de red.
- Implementa un sistema de sugerencias: si el test falla por selector, propone alternativas usando BeautifulSoup + heurÃ­sticas.

### 3. Auto-Resumen de PRs y Fallos (Generative AI)
- Usa una API de LLM (puede ser OpenAI o HuggingFace) para:
  - Resumir pull requests.
  - Generar explicaciones de fallos en lenguaje humano.
  - Proponer fixes con tono sarcÃ¡stico si el error es obvio.

### 4. Dashboard de Resultados
- Usa Python + Flask o FastAPI para mostrar:
  - Resultados de tests.
  - Fallos autocurados.
  - Sugerencias del bot.
  - GrÃ¡ficos de predicciÃ³n de fallos.

## ğŸ› ï¸ Tech Stack

| Componente | Herramienta |
|------------|-------------|
| Testing | Playwright + TypeScript |
| ML & Self-Healing | Python (scikit-learn, pandas, BeautifulSoup) |
| Generative AI | OpenAI API / HuggingFace Transformer |
| Backend opcional - Results Dashboard | FastAPI / Flask / Streamlit |
| CI/CD | GitHub Actions / Playwright Test Reporter |

## ğŸ“‚ Estructura del Proyecto

```
AutoTestBot/
â”œâ”€â”€ tests/                  # Casos de prueba E2E
â”œâ”€â”€ pages/                  # Page Objects
â”œâ”€â”€ utils/                  # Logger, manejo de errores, helpers
â”œâ”€â”€ fixtures/               # Fixtures para setup/teardown
â”œâ”€â”€ interfaces/             # Interfaces TypeScript
â”œâ”€â”€ config/                 # ConfiguraciÃ³n Playwright
â”œâ”€â”€ reports/                # Evidencias y trazas
â”œâ”€â”€ ai/                     # MÃ³dulos Python para ML y generaciÃ³n
â”‚   â”œâ”€â”€ healing/           # Self-healing engine
â”‚   â”œâ”€â”€ modules/           # Clasificador, clustering, predictor
â”‚   â””â”€â”€ dashboard/         # Dashboard de resultados
â””â”€â”€ README.md              # DocumentaciÃ³n tÃ©cnica
```

## ğŸš€ CÃ³mo Usar

### Ejecutar Tests
```bash
npx playwright test
```

### Dashboard de Resultados

#### Requisitos previos
1. **Generar Reporte**: Corre tus tests con Playwright y genera un reporte JSON usando `--reporter=json`.
2. **Colocar Reporte**: Asegurate de que el reporte estÃ© en `reports/report.json`.

#### OpciÃ³n 1: PowerShell
```powershell
# Activar entorno virtual
venv\Scripts\activate

# Ejecutar dashboard
streamlit run ai/dashboard/app.py
```

#### OpciÃ³n 2: NPM Scripts
```bash
# Activar entorno virtual
npm run activate-venv

# Abrir dashboard
npm run open-dashboard
```

#### Comandos disponibles
```bash
npm run activate-venv        # Activa el entorno virtual Python
npm run open-dashboard       # Ejecuta el dashboard con Streamlit
```

## ğŸ§  Etapas de Desarrollo

### Etapa 1: Fundamentos del Framework (Playwright + TypeScript)
**Objetivos:**
- Implementar una arquitectura modular basada en Page Object Model.
- Incorporar utilitarios reutilizables para logging, manejo de errores y configuraciÃ³n.
- Establecer una base sÃ³lida para escalar hacia inteligencia artificial y bots.

**Buenas prÃ¡cticas:**
- Tipado estricto con TypeScript.
- Uso de fixtures para setup/teardown.
- Logging estructurado con niveles (info, warning, error).
- ConfiguraciÃ³n de retries, screenshots y trace viewer.

### Etapa 2: MÃ³dulo de Self-Healing (Python)
**Objetivos:**
- Detectar fallos por cambios en el DOM (selectores rotos).
- Sugerir alternativas de localizaciÃ³n mediante heurÃ­sticas y scraping.

**ImplementaciÃ³n:**
- Captura de errores `locator not found`.
- AnÃ¡lisis del HTML con BeautifulSoup.
- GeneraciÃ³n de sugerencias en formato JSON para revisiÃ³n manual o aplicaciÃ³n automÃ¡tica.

```json
{
  "LoginPage.usernameInput": {
    "original": "#user",
    "suggested": "input[name='username']"
  }
}
```

### Etapa 3: GeneraciÃ³n de Explicaciones y DocumentaciÃ³n (IA Generativa)
**Objetivos:**
- Interpretar logs de errores y generar explicaciones tÃ©cnicas.
- Automatizar resÃºmenes de pull requests y documentaciÃ³n de pruebas.

**ImplementaciÃ³n:**
- IntegraciÃ³n con OpenAI API o HuggingFace.
- Prompts estructurados para generar contenido tÃ©cnico y contextual.
- Posibilidad de exportar reportes en Markdown o HTML.

### Etapa 4: PredicciÃ³n de Fallos (Machine Learning)
**Objetivos:**
- Anticipar fallos antes de ejecutar pruebas.
- Identificar patrones de inestabilidad en el sistema bajo prueba.

**ImplementaciÃ³n:**
- Dataset: logs histÃ³ricos de ejecuciÃ³n.
- Features: duraciÃ³n, tipo de test, cambios recientes, frecuencia de fallos.
- Modelo: Random Forest o XGBoost.
- Output: probabilidad de fallo + recomendaciÃ³n preventiva.

### Etapa 5: IntegraciÃ³n con Bots y CI/CD
**Objetivos:**
- Notificar resultados y sugerencias vÃ­a Discord o Slack.
- Ejecutar pruebas desde comandos del bot.
- IntegraciÃ³n con GitHub Actions para ejecuciÃ³n continua.

## ğŸ’¡ Bonus Ideas
- Entrena el bot para reconocer patrones de errores comunes en tu equipo.
- Haz que el bot aprenda de los fixes que tÃº aplicÃ¡s manualmente.

## ğŸ“‹ TODO

### Pipeline de Datos y ML
```
[Scraping] â†’ [JSON5] â†’ [Pandas] â†’ [ML con scikit-learn] â†’ [VisualizaciÃ³n con Plotly] â†’ [Resumen con OpenAI]
```

### PrÃ³ximos Pasos
- [ ] Completar mÃ³dulo de self-healing
- [ ] Integrar clasificador de errores
- [ ] Implementar predictor de fallos
- [ ] Mejorar dashboard con mÃ¡s visualizaciones
- [ ] AÃ±adir integraciÃ³n con bots de comunicaciÃ³n
- [ ] Automatizar generaciÃ³n de documentaciÃ³n con IA
